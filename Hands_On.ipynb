{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "959UpeTdFNLv"
   },
   "source": [
    "# Mount Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "kshMiO3DFNLx",
    "outputId": "8a4a93d0-811d-4d81-a7a2-4db78f1dba11"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4frtrx24nfvo"
   },
   "source": [
    "# Clone the main repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k62LYxhknJsU",
    "outputId": "fa58a107-c844-498f-ab66-1651c6c36d7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Hands-On-SuperNormal' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/arielz001/Hands-On-SDM.git\n",
    "!cd Hands-On-SDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlUJLz9mGnUF"
   },
   "source": [
    "### Download pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:45:30.041091Z",
     "start_time": "2025-12-07T19:45:18.558176Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOgoTFCfGm_H",
    "outputId": "212bfedb-92cc-4a5f-9112-e952fea66a3d"
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown \"https://drive.google.com/uc?id=1VX-Kg8yrFLgTGVLdVFuPYuE9lLecLmOb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:49:44.907592Z",
     "start_time": "2025-12-07T19:49:41.262554Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGuHEaL7HagD",
    "outputId": "01f3f1ab-3750-4488-fb95-98cd8b1a02e4"
   },
   "outputs": [],
   "source": [
    "!unzip checkpoint.zip\n",
    "!mv ./checkpoint ./SDM-UniPS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiGcJzTZntnm"
   },
   "source": [
    "# Now, we are going to take images with the camera and take your flashlight of your cellphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First: Write the name of your object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:52:25.738718Z",
     "start_time": "2025-12-07T19:51:17.705955Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1qn9DgrhecG",
    "outputId": "1708922e-cb92-496d-e2d5-c1f233a39b90"
   },
   "outputs": [],
   "source": [
    "obj_name = input(\"Add object's name: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are using COLAB you should run this code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:15:19.886966Z",
     "start_time": "2025-12-03T23:15:13.723626Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "pMzeOUidngwZ",
    "outputId": "3d8fbf80-6258-44df-a858-5cfe68ecdebf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab import output\n",
    "import base64\n",
    "import PIL.Image\n",
    "import io\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "js = \"\"\"\n",
    "async function takePhoto() {\n",
    "  const div = document.createElement('div');\n",
    "  const capture = document.createElement('button');\n",
    "  capture.textContent = 'Capture';\n",
    "  div.appendChild(capture);\n",
    "  document.body.appendChild(div);\n",
    "\n",
    "  const video = document.createElement('video');\n",
    "  video.style.display = 'block';\n",
    "  const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "  video.srcObject = stream;\n",
    "  video.play();\n",
    "  div.appendChild(video);\n",
    "\n",
    "  await new Promise((resolve) => capture.onclick = resolve);\n",
    "  const canvas = document.createElement('canvas');\n",
    "  canvas.width = video.videoWidth;\n",
    "  canvas.height = video.videoHeight;\n",
    "  canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "  stream.getTracks().forEach(track => track.stop());\n",
    "  div.remove();\n",
    "  return canvas.toDataURL('image/jpeg', 0.9);\n",
    "}\n",
    "\"\"\"\n",
    "def take_photo():\n",
    "    vista = input(\"Add view's number: \")\n",
    "    dirdata = f\"SDM-UniPS/data\"\n",
    "    !mkdir {dirdata}\n",
    "    dir = f\"SDM-UniPS/data/{obj_name}\"\n",
    "    !mkdir {dir}\n",
    "    dir2 = f\"{dir}/{vista}.data\"\n",
    "    !mkdir {dir2}\n",
    "    for light in range(10):\n",
    "      display(Javascript(js))\n",
    "      data = output.eval_js('takePhoto()')\n",
    "      img_data = base64.b64decode(data.split(\",\")[1])\n",
    "      image = PIL.Image.open(io.BytesIO(img_data))\n",
    "    \n",
    "      filename = f\"{dir2}/L ({light}).png\"\n",
    "      light += 1\n",
    "      image.save(filename)\n",
    "      print(f\"Saved image as: {filename}\")\n",
    "\n",
    "    \n",
    "take_photo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF you are using your local machine, you can take images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:43:35.577853Z",
     "start_time": "2025-12-07T20:43:31.772628Z"
    }
   },
   "outputs": [],
   "source": [
    "obj_name = input(\"Add object's name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:08:26.596509Z",
     "start_time": "2025-12-07T21:08:02.389769Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "vista = input(\"Add view's number: \")\n",
    "\n",
    "base_dir = \"SDM-UniPS/data\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "obj_dir = os.path.join(base_dir, obj_name)\n",
    "os.makedirs(obj_dir, exist_ok=True)\n",
    "vista_dir = os.path.join(obj_dir, f\"{vista}.data\")\n",
    "os.makedirs(vista_dir, exist_ok=True)\n",
    "\n",
    "avg_images_dir = f\"{obj_dir}/average_lights\"\n",
    "os.makedirs(avg_images_dir, exist_ok=True)\n",
    "\n",
    "# you should select the index of your camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cam is not able to open\")\n",
    "\n",
    "\n",
    "for luz in range(10):\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        cv2.imshow(\"Press 'c' to capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            filename = os.path.join(vista_dir, f\"L ({luz}).png\")\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Saved Image as: {filename}\")\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVy3-773yGpV"
   },
   "source": [
    "# Generate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:02:09.104717Z",
     "start_time": "2025-12-07T20:02:02.112319Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXv24KVt5VR-",
    "outputId": "551abd6e-c282-46b1-bdbd-0cd09a0c4e72"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers segmentation_refinement\n",
    "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "!pip install opencv-python pycocotools matplotlib\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRFSRbOHI9g6"
   },
   "source": [
    "#### Now, We are going to generate masks to estimate normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:02:21.139301Z",
     "start_time": "2025-12-07T20:02:15.364165Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cq9FnMo2rLYi",
    "outputId": "2d455a3b-32f0-41e8-a4a5-473c8ead2067"
   },
   "outputs": [],
   "source": [
    "!wget -O sam_vit_b_01ec64.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate mask is difficult with hsv in a real environment and *segment anything network* (SAM) is not sufficient for this task.\n",
    "\n",
    "#### So, we are going to use a different approach to generate the mask.\n",
    "\n",
    "#### We will use the *depth anything network* to generate the depth map, and in the depth image is easier to generate the mask with SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:11:44.704963Z",
     "start_time": "2025-12-07T21:10:42.343514Z"
    }
   },
   "outputs": [],
   "source": [
    "### import cv2\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import torch\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "sam.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import cv2\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# DEPTH ANYTHING (transfomers pipeline)\n",
    "# --------------------------------------------------\n",
    "pipe = pipeline(\n",
    "    task=\"depth-estimation\",\n",
    "    model=\"depth-anything/Depth-Anything-V2-Small-hf\"\n",
    ")\n",
    "\n",
    "def get_depth(image_pil):\n",
    "    depth_pil = pipe(image_pil)[\"depth\"]  # PIL Image\n",
    "    depth_np = np.array(depth_pil).astype(np.float32)\n",
    "    print(f\"[INFO] depth map:\", depth_np.shape)\n",
    "    return depth_np\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# INPUT\n",
    "# --------------------------------------------------\n",
    "vista = input(\"Add view's number to mask: \")\n",
    "\n",
    "img_path = f\"SDM-UniPS/data/{obj_name}/{vista}.data/L (6).png\"\n",
    "print(\"Files inside folder:\")\n",
    "!ls \"SDM-UniPS/data/{obj_name}/{vista}.data/\"\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load image\n",
    "# --------------------------------------------------\n",
    "\n",
    "img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# DEPTH\n",
    "# --------------------------------------------------\n",
    "depth_map = get_depth(Image.fromarray(img_rgb))\n",
    "\n",
    "# Normalize Depth\n",
    "depth_norm = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
    "depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "depth_rgb = cv2.cvtColor(depth_uint8, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# LOAD SAM\n",
    "# --------------------------------------------------\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    sam,\n",
    "    points_per_side=30,\n",
    "    pred_iou_thresh=0.88,\n",
    "    stability_score_thresh=0.92,\n",
    "    min_mask_region_area=10\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# RUN SAM ON DEPTH MAP\n",
    "# --------------------------------------------------\n",
    "print(\"[INFO] Generating SAM masks on depth map...\")\n",
    "masks = mask_generator.generate(depth_rgb)\n",
    "print(f\"[INFO] Total masks: {len(masks)}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# SHOW MASKS\n",
    "# --------------------------------------------------\n",
    "mask_dict = {}\n",
    "max_masks = min(len(masks), 24)\n",
    "n_cols, n_rows = 3,8\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 30))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(max_masks):\n",
    "    m = masks[idx]\n",
    "    mask_uint8 = (m['segmentation'].astype(np.uint8) * 255)\n",
    "\n",
    "    display_img = depth_rgb.copy()\n",
    "    display_img[mask_uint8 > 0] = [0, 255, 0] \n",
    "\n",
    "    axes[idx].imshow(display_img)\n",
    "    axes[idx].set_title(f\"{idx}\", fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "    mask_dict[idx] = mask_uint8\n",
    "\n",
    "for ax in axes[max_masks:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# SELECT ONE MASK AND SAVE\n",
    "# --------------------------------------------------\n",
    "selected_idx = int(input(f\"Select SAM mask index (0-{max_masks-1}): \"))\n",
    "selected_mask = mask_dict[selected_idx]\n",
    "\n",
    "mask_path = f\"SDM-UniPS/data/{obj_name}/{vista}.data/mask.png\"\n",
    "cv2.imwrite(mask_path, selected_mask)\n",
    "print(f\"[INFO] Saved mask {selected_idx} â†’ {mask_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgu9hknCAGjx"
   },
   "source": [
    "### Get Normals from SDM Uni-PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:12:10.727216Z",
     "start_time": "2025-12-07T21:11:48.969345Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMN4Pfe4ch6v",
    "outputId": "0d457b8a-0a34-4840-a316-5ce7758fd2f8"
   },
   "outputs": [],
   "source": [
    "!python SDM-UniPS/main.py \\\n",
    "    --session_name SDM-UniPS/results/{obj_name}  \\\n",
    "    --test_dir SDM-UniPS/data/{obj_name} \\\n",
    "    --checkpoint SDM-UniPS/checkpoint/ \\\n",
    "    --target normal_and_brdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show normals and base color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_results = f'results/{obj_name}'\n",
    "\n",
    "color_base = f'{path_results}/baseColor.png'\n",
    "color_rough = f'{path_results}/roughness.png'\n",
    "color_metal = f'{path_results}/metallic.png'\n",
    "normals = f'{path_results}/normal.png'\n",
    "\n",
    "images = [color_base, color_rough, color_metal, normals]\n",
    "titles = ['Base Color', 'Roughness', 'Metallic', 'Normals']\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for i, img_path in enumerate(images):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    ax[row, col].imshow(img)\n",
    "    ax[row, col].set_title(titles[i])\n",
    "    ax[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also relight the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:22:58.043571Z",
     "start_time": "2025-12-07T20:22:48.296881Z"
    }
   },
   "outputs": [],
   "source": [
    "!python SDM-UniPS/relighting.py --datadir ./SDM-UniPS/results/{obj_name}/results/0.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Map Generation from a Normal Map\n",
    "\n",
    "To generate a depth map from a normal map, there are several approaches. The most common method is the Frankot-Chellappa integration, although any consistent integration technique can work well.\n",
    "\n",
    "In this example, we solve the problem using a **least-squares system** that estimates the depth $z(x,y)$ from the gradients derived from the normal map:\n",
    "\n",
    "$$\n",
    "p = \\frac{\\partial z}{\\partial x} = -\\frac{n_x}{n_z}, \\quad \n",
    "q = \\frac{\\partial z}{\\partial y} = -\\frac{n_y}{n_z}\n",
    "$$\n",
    "\n",
    "A sparse linear system is constructed, including local constraints for each valid pixel according to the object mask. For each pixel, constraints with its neighbors (top, bottom, left, and right) are imposed, resulting in an over-determined system $A z = b$.\n",
    "\n",
    "Finally, the depth is obtained by solving the system using **sparse least squares** (`scipy.sparse.linalg.lsmr`). The solution is normalized so that the minimum depth is zero, and the mask is applied to set pixels outside the object to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:12:30.959888Z",
     "start_time": "2025-12-07T21:12:30.939162Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "\n",
    "def comp_depth_4edge_sparse(mask, normal):\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()\n",
    "    if isinstance(normal, torch.Tensor):\n",
    "        normal = normal.cpu().numpy()\n",
    "\n",
    "    h, w = mask.shape\n",
    "    n_pixels = h * w\n",
    "\n",
    "    mask = (mask > 0.5).astype(np.float32)\n",
    "    indices = lambda i, j: i * w + j\n",
    "\n",
    "    nx = normal[:, :, 0].flatten()\n",
    "    ny = normal[:, :, 1].flatten()\n",
    "    nz = normal[:, :, 2].flatten() + 1e-8\n",
    "\n",
    "    # take gradients\n",
    "    p = -nx / nz\n",
    "    q = -ny / nz\n",
    "\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    b = []\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if mask[i, j] == 0:\n",
    "                continue\n",
    "            idx = indices(i, j)\n",
    "\n",
    "            # here we put restrictions on the gradients for the noise in normals \n",
    "            if j < w - 1 and mask[i, j + 1] == 1:\n",
    "                idx_r = idx + 1\n",
    "                rows += [len(b), len(b)]\n",
    "                cols += [idx, idx_r]\n",
    "                data += [-1, 1]\n",
    "                b.append(p[idx])\n",
    "\n",
    "            if i < h - 1 and mask[i + 1, j] == 1:\n",
    "                idx_d = idx + w\n",
    "                rows += [len(b), len(b)]\n",
    "                cols += [idx, idx_d]\n",
    "                data += [-1, 1]\n",
    "                b.append(q[idx])\n",
    "\n",
    "            if j > 0 and mask[i, j - 1] == 1:\n",
    "                idx_l = idx - 1\n",
    "                rows += [len(b), len(b)]\n",
    "                cols += [idx, idx_l]\n",
    "                data += [1, -1]\n",
    "                b.append(p[idx])\n",
    "\n",
    "            if i > 0 and mask[i - 1, j] == 1:\n",
    "                idx_u = idx - w\n",
    "                rows += [len(b), len(b)]\n",
    "                cols += [idx, idx_u]\n",
    "                data += [1, -1]\n",
    "                b.append(q[idx])\n",
    "\n",
    "    A = scipy.sparse.coo_matrix((data, (rows, cols)), shape=(len(b), n_pixels))\n",
    "    b = np.array(b)\n",
    "\n",
    "    AtA = A.T @ A\n",
    "    Atb = A.T @ b\n",
    "    # x = scipy.sparse.linalg.spsolve(AtA, Atb)\n",
    "    # We could solve it with LSMR or other solvers\n",
    "    x = scipy.sparse.linalg.lsmr(A, b)[0]\n",
    "\n",
    "\n",
    "    depth = x.reshape(h, w)\n",
    "    depth -= depth.min()\n",
    "    depth[mask == 0] = 0.0\n",
    "\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:12:33.732284Z",
     "start_time": "2025-12-07T21:12:33.722099Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import obj_functions as ob\n",
    "\n",
    "def depth_process(normal, mask=None, albedo=None, path=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(normal[:, :, 0].shape, dtype=np.uint8) * 255\n",
    "    normal[mask == 0] = [0.0, 0.0, 0.0]\n",
    "    print(f\"mask.shape in depth_process: {mask.shape}\")\n",
    "    normal[:, :, 1] = normal.copy()[:, :, 1] * -1\n",
    "\n",
    "    # solve depth\n",
    "    depth = comp_depth_4edge_sparse(mask, normal)\n",
    "\n",
    "    if depth.ndim == 2:\n",
    "        depth = depth[:, :, None]\n",
    "\n",
    "    # Depth to 3D\n",
    "    ver, tri = ob.Depth2VerTri(depth, mask)\n",
    "    temp_albedo = albedo.astype(np.uint8)\n",
    "    ob.save_as_ply(f\"{path}/normals_3D.ply\", depth, normal, temp_albedo, mask, tri)\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-07T21:14:15.302430Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def normals2depth(path_results, path_mask):\n",
    "    \n",
    "    for vista in os.listdir(path_results):\n",
    "\n",
    "        normal = plt.imread(os.path.join(path_results, vista, 'normal.png')).astype(np.float32)\n",
    "        normal = normal[:, :, :3]  # if this have alpha\n",
    "        normal = normal * 2.0 - 1.0  # normalize\n",
    "\n",
    "        mask = cv2.imread(os.path.join(path_mask, vista, 'mask.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        color_img = cv2.imread(os.path.join(path_results, 'baseColor.png'), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        normals = normal.copy()\n",
    "        normals[mask == 0] = 0\n",
    "\n",
    "        depth = depth_process(normals, mask, albedo=color_img, path=os.path.join(path_results, vista))\n",
    "\n",
    "        plt.imshow(depth, cmap='gray')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals2depth(f'SDM-UniPS/results/{obj_name}/results', path_mask=f'SDM-UniPS/data/{obj_name}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
